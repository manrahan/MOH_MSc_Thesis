{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f213685d-a844-4dae-8f85-56b4c860cbe0",
   "metadata": {
    "id": "f213685d-a844-4dae-8f85-56b4c860cbe0"
   },
   "source": [
    "# Creation of Land Use Change Tables from Generated Google Earth Assets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c49908-01de-46e7-9518-1f5997ede969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is:  2023-05-20 14:35:10.103503\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import geemap.ml as ml\n",
    "from ipygee import chart as chart\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pymannkendall as mk\n",
    "import xarray as xr\n",
    "import os\n",
    "# Import date class from datetime module\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "today = dt.today()\n",
    "print(\"Today is: \", today)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb97ec-c96b-4312-9908-67f52483ec8f",
   "metadata": {},
   "source": [
    "# GEE Authentication \n",
    " \n",
    " ### Paste the Authetication code into the box below if prompted to save token\n",
    " \n",
    " \n",
    " (press enter to save token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5559b136-6061-4ea2-ad3d-5c8cf9f927eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4ac507-28df-4313-a67c-2db9fb8681ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "geemap.ee_initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5173d2-6427-4ac7-92c7-8230d1fe0ee1",
   "metadata": {},
   "source": [
    "### New version control of inputs and outputs\n",
    "\n",
    "* best to check that catchment hydroclimatic information is indeed the most reliable/latest available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dce165c-0e65-44be-b541-994dd9b4a4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 catchments processed for hydroclimatic variables:\n",
      " \n",
      "[17005, 18001, 20007, 21017, 21023, 21024, 22001, 23004, 24004, 25006, 26003, 27035, 27042, 27047, 27051, 27071, 28046, 28072, 29003, 29009, 30004, 30012, 30015, 31023, 32003, 33018, 33019, 33029, 34011, 36003, 36009, 36010, 37005, 38026, 39017, 39019, 39020, 39025, 39034, 40005, 40011, 41022, 41025, 41027, 41029, 42003, 43014, 45005, 46003, 46005, 47009, 48003, 48004, 49004, 50002, 52010, 52016, 53006, 53008, 53009, 53017, 54008, 54018, 54025, 54034, 54036, 55008, 55014, 55016, 55026, 55029, 56013, 57004, 60002, 60003, 62001, 64001, 65005, 67010, 67018, 68005, 71001, 71004, 72005, 73005, 73011, 75017, 76014, 77004, 78004, 79002, 79004, 8009, 93001, 94001]\n"
     ]
    }
   ],
   "source": [
    "# set the path and version of the input data\n",
    "p = '..'\n",
    "version = 'Version_3_20230303'\n",
    "\n",
    "# read in the list of catchment IDs from the input csv file\n",
    "l = pd.read_csv(f\"{p}/Inputs/{version}/GB.csv\").ID\n",
    "\n",
    "# display the list of catchment IDs and convert it to a Python list\n",
    "names = l.tolist()\n",
    "\n",
    "# names = [22001, 23004, 71004, 79002, 94001]\n",
    "\n",
    "# print the number of catchments and their IDs\n",
    "print(f'{len(names)} catchments processed for hydroclimatic variables:\\n \\n{names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be9e09-35db-4adb-92c7-5ebc78e231da",
   "metadata": {},
   "source": [
    "\n",
    "### Load the JS Module\n",
    "\n",
    "The custom JS module takes the difficult javascript functions that do not translate well to python, and makes them callable in the notebook environment. \n",
    "\n",
    "Current version 6 improves the classifier by using a weighted training strategy.\n",
    "\n",
    "This custom module borrows some functions from the LandTrendr module developed by Justin Braaten (Google) which is classified under an apache license i.e. free for use). The adaptation begins from landTrendr version 0.2 which incorporated Landsat Collection 2, removing the need for regression coefficients between sensors developed by roy et. al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c702bf6-33c6-4c28-ba17-2eb15870d719",
   "metadata": {
    "id": "e6157fac-15c5-4016-b24e-3729960e6844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT! Please be advised:\n",
      "- This version of the Adapted_LT.js modules\n",
      "  uses some code adapted from the aut/or: @author Justin Braaten (Google) * @author Zhiqiang Yang (USDA Forest Service) * @author Robert Kennedy (Oregon State University)\n",
      "The latest edits to this code occur: 08/03/2023 for the adaptation efforts by @Mike OHanrahan (TU DELFT MSc research)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'version': 'string',\n",
       " 'buildSensorYearCollection': 'function',\n",
       " 'getSRcollection': 'function',\n",
       " 'getCombinedSRcollection': 'function',\n",
       " 'buildSRcollection': 'function',\n",
       " 'getCollectionIDlist': 'function',\n",
       " 'countClearViewPixels': 'function',\n",
       " 'buildClearPixelCountCollection': 'function',\n",
       " 'removeImages': 'function',\n",
       " 'LAIcol': 'function',\n",
       " 'calcIndex': 'function',\n",
       " 'standardize': 'function',\n",
       " 'transformSRcollection': 'function',\n",
       " 'createTrainingImage': 'function',\n",
       " 'addTerrainBand': 'function',\n",
       " 'genGCP': 'function',\n",
       " 'classifier': 'function',\n",
       " 'classArea': 'function',\n",
       " 'imcolFromAsset': 'function',\n",
       " 'imcolFromAssetHILDA': 'function',\n",
       " 'unionCollections': 'function'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oeel = geemap.requireJS()\n",
    "\n",
    "Map = geemap.Map()\n",
    "\n",
    "ltgee = geemap.requireJS(r'../JS_module/Adapted_LT_v8.2.js')\n",
    "\n",
    "ltgee.availability  #all functions within the javascript module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484acd26-c655-4081-87b5-756c24f92c7a",
   "metadata": {},
   "source": [
    "## Initiate With a Shapefile\n",
    "\n",
    "This notebook assumes the user has a shapefile saved as an asset on their GEE, the assets used in the CATAPUCII project will be made publicly available in the @mohanrahan repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7869510d-cc72-4894-b0e6-84a695ac142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where assets are stored\n",
    "asset_dir = 'projects/mohanrahan/assets'\n",
    "\n",
    "# Asset ID for catchment boundaries\n",
    "catchment_asset = 'CATAPUCII_Catchments/CAMELS_GB_catchment_boundaries'\n",
    "\n",
    "# Name of the dataset\n",
    "dataset = 'CAMELS_GB'\n",
    "\n",
    "# Column string to identify catchments\n",
    "col_string  = 'ID'\n",
    "\n",
    "# Coordinate reference system, GB is british national grid\n",
    "crs = 'EPSG:27700'\n",
    "\n",
    "# Figure number for plotting\n",
    "fignum = 0\n",
    "\n",
    "# RGB visualization settings for Landsat imagery\n",
    "RGB_VIS = {'bands':['B3','B2','B1'], 'min':0, 'max':1.5e3}\n",
    "\n",
    "#Classified image visualisation\n",
    "lc_vis = {'bands':['landcover'], 'min':1, 'max':5, 'palette':['#E6004D', '#FFFFA8', '#80FF00', '#A6A6FF', '#00CCF2']}\n",
    "\n",
    "# Start and end years for Landsat data collection\n",
    "startYear = 1899\n",
    "\n",
    "endYear = 2019\n",
    "\n",
    "\n",
    "# Start and end days for Landsat data collection\n",
    "startDay = '06-20'\n",
    "endDay = '08-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24017ee3-b207-447c-938e-200892cfed46",
   "metadata": {},
   "source": [
    "## The Table Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338807d0-5874-4a83-9acf-9ce55147e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataframe generated from the EE asset 95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_area</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>VERSION</th>\n",
       "      <th>ID</th>\n",
       "      <th>EXPORTED</th>\n",
       "      <th>ID_STRING</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000000000000000088</th>\n",
       "      <td>1355.679450</td>\n",
       "      <td>1349.764903</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27071</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>27071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000000000000235</th>\n",
       "      <td>1145.767150</td>\n",
       "      <td>1140.885961</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>71001</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>71001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000000000000001c0</th>\n",
       "      <td>1125.603290</td>\n",
       "      <td>1121.172318</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>54008</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>54008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000000000000207</th>\n",
       "      <td>897.948531</td>\n",
       "      <td>894.478359</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>62001</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>62001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000000000000025a</th>\n",
       "      <td>798.157955</td>\n",
       "      <td>794.507522</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>79002</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>79002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000000000000021b</th>\n",
       "      <td>12.768404</td>\n",
       "      <td>12.719149</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67010</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>67010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000000000000082</th>\n",
       "      <td>11.353532</td>\n",
       "      <td>11.304831</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27047</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>27047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000000000000001df</th>\n",
       "      <td>10.506362</td>\n",
       "      <td>10.466687</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>55008</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>55008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000000000000084</th>\n",
       "      <td>8.177400</td>\n",
       "      <td>8.143164</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27051</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>27051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000000000000000c6</th>\n",
       "      <td>4.316773</td>\n",
       "      <td>4.299710</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>31023</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>31023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pixel_area     area_km2                       SOURCE  \\\n",
       "system_index                                                                  \n",
       "00000000000000000088  1355.679450  1349.764903  National River Flow Archive   \n",
       "00000000000000000235  1145.767150  1140.885961  National River Flow Archive   \n",
       "000000000000000001c0  1125.603290  1121.172318  National River Flow Archive   \n",
       "00000000000000000207   897.948531   894.478359  National River Flow Archive   \n",
       "0000000000000000025a   798.157955   794.507522  National River Flow Archive   \n",
       "...                           ...          ...                          ...   \n",
       "0000000000000000021b    12.768404    12.719149  National River Flow Archive   \n",
       "00000000000000000082    11.353532    11.304831  National River Flow Archive   \n",
       "000000000000000001df    10.506362    10.466687  National River Flow Archive   \n",
       "00000000000000000084     8.177400     8.143164  National River Flow Archive   \n",
       "000000000000000000c6     4.316773     4.299710  National River Flow Archive   \n",
       "\n",
       "                     VERSION     ID       EXPORTED ID_STRING  \n",
       "system_index                                                  \n",
       "00000000000000000088     1.3  27071  1518422400000     27071  \n",
       "00000000000000000235     1.3  71001  1518422400000     71001  \n",
       "000000000000000001c0     1.3  54008  1518422400000     54008  \n",
       "00000000000000000207     1.3  62001  1518422400000     62001  \n",
       "0000000000000000025a     1.3  79002  1518422400000     79002  \n",
       "...                      ...    ...            ...       ...  \n",
       "0000000000000000021b     1.3  67010  1518422400000     67010  \n",
       "00000000000000000082     1.3  27047  1518422400000     27047  \n",
       "000000000000000001df     1.3  55008  1518422400000     55008  \n",
       "00000000000000000084     1.3  27051  1518422400000     27051  \n",
       "000000000000000000c6     1.3  31023  1518422400000     31023  \n",
       "\n",
       "[95 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = ee.FeatureCollection(f\"{asset_dir}/{catchment_asset}\")\n",
    "\n",
    "def set_area_km2(feature):\n",
    "    '''\n",
    "    Calculate the area of each geometry in square kilometer\n",
    "    '''\n",
    "    area = feature.geometry().area().divide(1000*1000)\n",
    "    setting = feature.set('area_km2', area)\n",
    "    return setting\n",
    "\n",
    "def set_area_pixel(feature):\n",
    "    aoi = feature.geometry()\n",
    "    area = ee.Image.pixelArea().divide(1e6).clip(aoi).select('area').reduceRegion(**{\n",
    "        'reducer':ee.Reducer.sum(),\n",
    "        'geometry':aoi,\n",
    "        'scale':30,\n",
    "        'crs':crs,\n",
    "        'maxPixels':1e13,\n",
    "        'bestEffort':True,\n",
    "        }).get('area')\n",
    "    setting = feature.set('pixel_area', area)\n",
    "    return setting\n",
    "\n",
    "def set_id(feature):\n",
    "    '''\n",
    "    Set the system ID as a column\n",
    "    '''\n",
    "    getting_name = ee.String(feature.get('system:index'))\n",
    "    setting_id = feature.set({'system_index':getting_name,})\n",
    "    return setting_id\n",
    "\n",
    "# Define a function to set the zone for a feature\n",
    "def set_zone(feature):\n",
    "    # Get the feature geometry\n",
    "    geometry = feature.geometry()\n",
    "    \n",
    "    # Check which zone the feature intersects with\n",
    "    if geometry.intersects(gn,1):\n",
    "        zone = 'N'\n",
    "        \n",
    "    elif geometry.intersects(gm,1):\n",
    "        zone = 'M'\n",
    "        \n",
    "    elif geometry.intersects(gs,1):\n",
    "        zone = 'S'\n",
    "        \n",
    "    else:\n",
    "        zone = 'Unknown'\n",
    "        \n",
    "    # Add the 'zone' property to the feature\n",
    "    return feature.set('zone', zone)\n",
    "\n",
    "table_area = table.map(set_area_km2).map(set_id).map(set_area_pixel)\n",
    "\n",
    "Filtered_Sorted = table_area.filter(ee.Filter.gt('area_km2', 0)).sort('pixel_area', False) #.map(set_zone) # true ranks from smallest to largest\n",
    "\n",
    "# # Set the 'zone' property for features in the north zone\n",
    "# fc_north = Filtered_Sorted.filterBounds(gn).map(lambda f: f.set('zone', 'N'))\n",
    "\n",
    "# # Set the 'zone' property for features in the middle zone\n",
    "# fc_middle = Filtered_Sorted.filterBounds(gm).map(lambda f: f.set('zone', 'M'))\n",
    "\n",
    "# # Set the 'zone' property for features in the south zone\n",
    "# fc_south = Filtered_Sorted.filterBounds(gs).map(lambda f: f.set('zone', 'S'))\n",
    "\n",
    "# Merge the three feature collections\n",
    "# fc_with_zones = ee.FeatureCollection(fc_north.merge(fc_middle).merge(fc_south)).sort('pixel_area', False)\n",
    "\n",
    "down = geemap.ee_to_pandas(Filtered_Sorted).set_index(['system_index'])\n",
    "\n",
    "df1 = down.loc[down[col_string].isin(names)]\n",
    "\n",
    "#df1.to_excel(f'../Outputs/{dataset}/{dataset}_catchment_table.xlsx')\n",
    "\n",
    "print(f'The length of the dataframe generated from the EE asset {len(df1)}')\n",
    "\n",
    "sys_index = df1.index.to_list()\n",
    "\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6ead43-8be1-4e43-b46d-d583d0c9c0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of catchments with Hydroclimatic indices calculated match the length filtered EE asset\n",
      "There seems to be no mismatch\n",
      "Continue... \n"
     ]
    }
   ],
   "source": [
    "len1 = len(df1[col_string].values)\n",
    "len2 = len(names)\n",
    "\n",
    "# geom_tup_ls = [('north_zone', geom_north), ('middle_zone', geom_middle), ('south_zone',geom_south)]\n",
    "\n",
    "# file_prefix = ['GB_Middle_HC_tuned_', 'GB_North_HC_tuned_', 'GB_South_HC_tuned_'] # f'{file_prefix}{year}'\n",
    " \n",
    "if len1 > len2:\n",
    "    print(f'catchment{ set(df1[col_string].values).symmetric_difference(names)} is/are missing from the catchment sets')\n",
    "elif len2 >len1:\n",
    "    print(f'catchment{ set(df1[col_string].values).symmetric_difference(names)} is/are missing from the EE asset')\n",
    "else:\n",
    "    print('The number of catchments with Hydroclimatic indices calculated match the length filtered EE asset\\nThere seems to be no mismatch\\nContinue... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7c2a5b-ed8f-4289-810e-2d7d6c5d8611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e949b8c33c5841f2ad2d6468bf13d7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[54.4666618785552, -2.562465661904664], controls=(WidgetControl(options=['position', 'transparent_b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aoi = Filtered_Sorted.geometry().bounds()\n",
    "\n",
    "imCol = ltgee.imcolFromAssetHILDA(startYear, endYear, aoi, dataset, \"projects/mohanrahan/assets/HILDA\")\n",
    "\n",
    "Map = geemap.Map()\n",
    "# Map.setOptions('')\n",
    "Map.addLayer(imCol.mode(), {'bands':['b1'], 'min':1, 'max':99, 'palette':['#E6004D', '#FFFFA8', '#80FF00', '#A6A6FF', '#00CCF2']}, 'Mode of Classes')\n",
    "Map.addLayer(aoi, {'color': 'green'}, 'green: Included')\n",
    "# Map.addLayer(naoi, {'color':'red'}, 'red: Not Included')\n",
    "Map.centerObject(aoi, 7)\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fffe039c-198a-4496-ad9b-eb2ab013b030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractArea(item):\n",
    "    \n",
    "    '''\n",
    "    Method borrowed from https://code.earthengine.google.co.in/9c45ff677c46eae08952831de02bfb40\n",
    "    Article: https://spatialthoughts.com/2020/06/19/calculating-area-gee/\n",
    "    '''\n",
    "    \n",
    "    areaDict = ee.Dictionary(item)\n",
    "    classNumber = ee.Number(areaDict.get('b1')).format()\n",
    "    area = ee.Number(areaDict.get('sum')).divide(1e6)\n",
    "    return ee.List([classNumber, area])\n",
    "\n",
    "def classArea(classified_image, scale, aoi):\n",
    "    '''\n",
    "    This function takes the pixel areas represented by each class the landsat scale is 30m but,\n",
    "    nominal scale of image is 111000m after medoid compositing\n",
    "    '''\n",
    "    \n",
    "    areaImage = ee.Image.pixelArea().addBands(classified_image)\n",
    "    \n",
    "    areas = areaImage.reduceRegion(**{\n",
    "            'reducer':ee.Reducer.sum().group(**{'groupField':1, 'groupName':'b1'}),\n",
    "            'geometry':aoi,\n",
    "            'scale':scale,\n",
    "            'maxPixels':1e10,\n",
    "            'bestEffort':True,\n",
    "    })\n",
    "    \n",
    "    classAreas = ee.List(areas.get('groups'))\n",
    "    \n",
    "    classAreasLists = classAreas.map(extractArea)\n",
    "    \n",
    "    return classAreasLists\n",
    "\n",
    "def dateToMs(year):\n",
    "    datetime_obj = datetime.datetime(year, 8, 31, 22, 0, 0)\n",
    "    return datetime_obj\n",
    "\n",
    "def dataframeAreas(i, yc, aoi, classified, trainingClassImage, ms, classImageYear, name, accuracy, pixArea):\n",
    "\n",
    "    ls1 = pd.DataFrame(classArea(classified, 1113, aoi).getInfo(), columns=['class', 'area_H'])\n",
    "    # ls2 = pd.DataFrame(classArea(trainingClassImage, 1000, aoi).getInfo(), columns=['class', 'area_CORINE'])\n",
    "\n",
    "    merged = ls1\n",
    "\n",
    "    merged['image_date'] = ms\n",
    "    pivoted = merged.pivot(index='image_date', columns='class', values=['area_H'])\n",
    "    pivoted['training', 'year_trained'] =  classImageYear\n",
    "\n",
    "    pivoted['catchment', 'area'] = pixArea\n",
    "    \n",
    "    # pivoted['area_RF', '6'] = pivoted.catchment.area - pivoted.iloc[0, 6:10].sum() \n",
    "    pivoted['catchment', 'name '] = name\n",
    "    # pivoted['testing', 'accuracy'] = accuracy\n",
    "    # pivoted['ind'] = str(i)+'_'+str(yc)\n",
    "    pivoted.fillna(0)\n",
    "    # print(pivoted)\n",
    "    return pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4186efd-fc78-40d9-80ad-4aae12bfc0ff",
   "metadata": {
    "id": "cc5da96b-d9f7-4042-b21c-1aed2be24d8e"
   },
   "source": [
    "## Running Module over the Shapefile\n",
    "\n",
    "1. The geometries are called by their system indices (sys_index) updating the 'aoi' and running the process over any  using the indices included in the \n",
    "2. The image collection is generated per shapefile and then returns the decadal mean of each index\n",
    "\n",
    "# TODO:\n",
    "\n",
    "- Redefine the methodology of reduction. Using chart --> dataframe --> join all dataframes is redundant an probably very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a2c7d4-b399-45df-a07a-c95fcd65fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "classLoopParams = {'dataset':'CORINE',    #training dataset, no other than corine currently supported\n",
    "               'trainingClassLevel':1, #classLevel determines the level of corine class simplification\n",
    "               'customClassLevels':None,   #can provide some custom levels, not fully tested\n",
    "               'numClasses':5,            #if trainingClassLevel is 1 then there are 5 classes, level is 2 then there are 15, 3 is 44. (CORINE land cover class grouping)\n",
    "               'tileScale':2,            #tileScale higher number reduces likelihood of classifier running into a memory limit\n",
    "               'year_classified': np.arange(2019, 2020),   # classification year is , for classifiers saved, the same as the years available in the training dataset\n",
    "              }\n",
    "\n",
    "output_folder = f'../Outputs/{dataset}/class_areas_from_asset_HILDA/'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    print(f'{output_folder} created')\n",
    "    os.makedirs(output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f09b73c9-3860-4b3c-bd46-50aa5f7cb23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000000000000000088'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1.ID==27071].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a04b3dc-3231-43ae-ae60-0c63d2ebe2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La Sormonne Belval\n",
    "catchment_ID_broken = 17005\n",
    "index_broken = df1[df1.ID==catchment_ID_broken].index.values[0]\n",
    "year_broken = 1899\n",
    "\n",
    "GB_decades = ('1970 - 1979', '1980 - 1989', '1990 - 1999', '2000 - 2009')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110fb734-dcbb-4ce6-af08-9fe6a55678af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin loop: 2023-05-20 14:36:30.484906\n",
      "resuming from broken\n",
      "30 / 95\n",
      "begin CAMELS_GB 17005 1899\n",
      "1899-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1930\n",
      "1930-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1950\n",
      "1950-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1960\n",
      "1960-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1970\n",
      "1970-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1979\n",
      "1979-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1980\n",
      "1980-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1984\n",
      "1984-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1985\n",
      "1985-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1986\n",
      "1986-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1987\n",
      "1987-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1988\n",
      "1988-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1989\n",
      "1989-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1990\n",
      "1990-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1991\n",
      "1991-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1992\n",
      "1992-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1993\n",
      "1993-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1994\n",
      "1994-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1995\n",
      "1995-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1996\n",
      "1996-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1997\n",
      "1997-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1998\n",
      "1998-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 1999\n",
      "1999-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2000\n",
      "2000-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2001\n",
      "2001-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2002\n",
      "2002-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2003\n",
      "2003-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2004\n",
      "2004-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2005\n",
      "2005-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2006\n",
      "2006-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2007\n",
      "2007-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2008\n",
      "2008-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2009\n",
      "2009-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2010\n",
      "2010-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2011\n",
      "2011-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2012\n",
      "2012-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2013\n",
      "2013-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2014\n",
      "2014-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2015\n",
      "2015-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2016\n",
      "2016-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2017\n",
      "2017-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2018\n",
      "2018-08-31 22:00:00\n",
      "begin CAMELS_GB 17005 2019\n",
      "2019-08-31 22:00:00\n",
      "step2: Done: 2023-05-20 14:46:31.280926, time taken: 0:10:00.793983\n",
      "\n",
      "Catchment: 17005, total time: 0:10:00.793983\n",
      "---------------\n",
      "31 / 95\n",
      "begin CAMELS_GB 54018 1899\n",
      "1899-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1930\n",
      "1930-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1950\n",
      "1950-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1960\n",
      "1960-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1970\n",
      "1970-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1979\n",
      "1979-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1980\n",
      "1980-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1984\n",
      "1984-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1985\n",
      "1985-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1986\n",
      "1986-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1987\n",
      "1987-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1988\n",
      "1988-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1989\n",
      "1989-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1990\n",
      "1990-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1991\n",
      "1991-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1992\n",
      "1992-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1993\n",
      "1993-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1994\n",
      "1994-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1995\n",
      "1995-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1996\n",
      "1996-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1997\n",
      "1997-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1998\n",
      "1998-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 1999\n",
      "1999-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2000\n",
      "2000-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2001\n",
      "2001-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2002\n",
      "2002-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2003\n",
      "2003-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2004\n",
      "2004-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2005\n",
      "2005-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2006\n",
      "2006-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2007\n",
      "2007-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2008\n",
      "2008-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2009\n",
      "2009-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2010\n",
      "2010-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2011\n",
      "2011-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2012\n",
      "2012-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2013\n",
      "2013-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2014\n",
      "2014-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2015\n",
      "2015-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2016\n",
      "2016-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2017\n",
      "2017-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2018\n",
      "2018-08-31 22:00:00\n",
      "begin CAMELS_GB 54018 2019\n",
      "2019-08-31 22:00:00\n",
      "step2: Done: 2023-05-20 14:56:12.135087, time taken: 0:09:40.852990\n",
      "\n",
      "Catchment: 54018, total time: 0:09:40.852990\n",
      "---------------\n",
      "32 / 95\n",
      "begin CAMELS_GB 55026 1899\n",
      "1899-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1930\n",
      "1930-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1950\n",
      "1950-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1960\n",
      "1960-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1970\n",
      "1970-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1979\n",
      "1979-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1980\n",
      "1980-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1984\n",
      "1984-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1985\n",
      "1985-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1986\n",
      "1986-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1987\n",
      "1987-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1988\n",
      "1988-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1989\n",
      "1989-08-31 22:00:00\n",
      "begin CAMELS_GB 55026 1990\n",
      "1990-08-31 22:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 57\u001b[0m\n\u001b[0;32m     52\u001b[0m ms \u001b[38;5;241m=\u001b[39m dateToMs(yc)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(ms)\n\u001b[1;32m---> 57\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdataframeAreas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maoi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassified\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNumber\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpix_area\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_HILDA.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m classArea_df \u001b[38;5;241m=\u001b[39m classArea_df\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "Cell \u001b[1;32mIn[10], line 41\u001b[0m, in \u001b[0;36mdataframeAreas\u001b[1;34m(i, yc, aoi, classified, trainingClassImage, ms, classImageYear, name, accuracy, pixArea)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataframeAreas\u001b[39m(i, yc, aoi, classified, trainingClassImage, ms, classImageYear, name, accuracy, pixArea):\n\u001b[1;32m---> 41\u001b[0m     ls1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mclassArea\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassified\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1113\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maoi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea_H\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# ls2 = pd.DataFrame(classArea(trainingClassImage, 1000, aoi).getInfo(), columns=['class', 'area_CORINE'])\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     merged \u001b[38;5;241m=\u001b[39m ls1\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\ee\\computedobject.py:98\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\ee\\data.py:738\u001b[0m, in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m workload_tag:\n\u001b[0;32m    736\u001b[0m   body[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworkloadTag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m workload_tag\n\u001b[1;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_api_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\ee\\data.py:328\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes a Cloud API call and translates errors to EEExceptions.\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m  EEException if the call fails.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    330\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\googleapiclient\\_helpers.py:134\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    133\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\googleapiclient\\http.py:900\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[0;32m    899\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 900\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    913\u001b[0m     callback(resp)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\googleapiclient\\http.py:177\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m http\u001b[38;5;241m.\u001b[39mrequest(uri, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    219\u001b[0m     uri,\n\u001b[0;32m    220\u001b[0m     method,\n\u001b[0;32m    221\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    222\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[0;32m    223\u001b[0m     redirections\u001b[38;5;241m=\u001b[39mredirections,\n\u001b[0;32m    224\u001b[0m     connection_type\u001b[38;5;241m=\u001b[39mconnection_type,\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    226\u001b[0m )\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[0;32m    236\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\httplib2\\__init__.py:1701\u001b[0m, in \u001b[0;36mHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[0;32m   1699\u001b[0m             content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1701\u001b[0m             (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1702\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcachekey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1703\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1705\u001b[0m     is_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(e, socket\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\httplib2\\__init__.py:1421\u001b[0m, in \u001b[0;36mHttp._request\u001b[1;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[0;32m   1419\u001b[0m     auth\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, headers, body)\n\u001b[1;32m-> 1421\u001b[0m (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mresponse(response, body):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\site-packages\\httplib2\\__init__.py:1373\u001b[0m, in \u001b[0;36mHttp._conn_request\u001b[1;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1373\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mBadStatusLine, http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mResponseNotReady):\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;66;03m# If we get a BadStatusLine on the first try then that means\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;66;03m# the connection just went stale, so retry regardless of the\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;66;03m# number of RETRIES set.\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seen_bad_status_line \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\BPD4a\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = dt.today()\n",
    "\n",
    "scale =1113\n",
    "\n",
    "print(f'begin loop: {t0}')\n",
    "\n",
    "classArea_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "index_broken = df1[df1[col_string] == catchment_ID_broken].index.tolist()[0]\n",
    "\n",
    "index = sys_index.index(index_broken)\n",
    "\n",
    "# Slice the list based on the length of the string\n",
    "slice_start = index\n",
    "slice_broken = index + sys_index.count(index_broken) -1\n",
    "\n",
    "\n",
    "\n",
    "for i, ind in enumerate(sys_index[slice_broken:]): # Loop through all indices in the system index\n",
    "    \n",
    "    year_range = [1899, 1930, 1950, 1960, 1970, 1979, 1980] + list(np.arange(1984, 2020))\n",
    "    \n",
    "    if ind == index_broken:\n",
    "        startYear = year_broken\n",
    "        year_range = year_range[year_range.index(startYear):]  # Update year_range starting from startYear\n",
    "        print('resuming from broken')\n",
    "    else:\n",
    "        year_range = year_range\n",
    "    \n",
    "    print(f'{slice_broken+i} / {len(sys_index)}')\n",
    "    \n",
    "    pix_area = df1.loc[ind, 'pixel_area']\n",
    "    \n",
    "    name = df1.loc[ind, col_string]\n",
    "    \n",
    "    aoi = Filtered_Sorted.filter(ee.Filter.eq('system_index', ind)).geometry()\n",
    "    \n",
    "    t1 = dt.today()\n",
    "    \n",
    "    if dataset == 'CAMELS_GB':\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        for j, yc in enumerate(year_range):\n",
    "            \n",
    "            print('begin', dataset, name, yc)\n",
    "            \n",
    "            #the image from the collection that we want to classify\n",
    "            classified = imCol.filterDate(str(yc+100)+'-'+startDay, str(yc+101)+'-'+endDay).first()\n",
    "        \n",
    "            ms = dateToMs(yc)\n",
    "           \n",
    "            print(ms)\n",
    "            \n",
    "         \n",
    "            df = dataframeAreas(i, yc, aoi, classified, ee.Image.constant(ee.Number(1)), ms, yc, f'{name}', 1, pix_area)\n",
    "            \n",
    "            df.to_excel(f'{output_folder}{name}_{yc}_HILDA.xlsx')\n",
    "            \n",
    "            \n",
    "                       \n",
    "            classArea_df = classArea_df.append(df)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('classification routine for this dataset is not yet provided for')\n",
    "    \n",
    "    t4 = dt.today()\n",
    "    \n",
    "    print(f'step2: Done: {t4}, time taken: {t4-t1}')\n",
    "    \n",
    "    print(f'\\nCatchment: {name}, total time: {t4-t1}\\n---------------')\n",
    "    \n",
    "\n",
    "\n",
    "tfinal = dt.today()\n",
    "\n",
    "print(f'END LOOP: Full routine finished: {tfinal} \\nTime taken: {tfinal-t0}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
