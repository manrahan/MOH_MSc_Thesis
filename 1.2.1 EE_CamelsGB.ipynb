{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f213685d-a844-4dae-8f85-56b4c860cbe0",
   "metadata": {
    "id": "f213685d-a844-4dae-8f85-56b4c860cbe0"
   },
   "source": [
    "# LandTrendr Implementation For Decadal Averaging of Spectral Indices\n",
    "\n",
    "### Requirements: \n",
    "\n",
    "Python:\n",
    "\n",
    "* geemap\n",
    "* ee\n",
    "* matplotlib\n",
    "* numpy\n",
    "* pandas\n",
    "* oeel ** \n",
    "\n",
    "Other:\n",
    "* Google Earth Engine Account\n",
    "\n",
    "The LandTrendr algorithm is highly efficient and extensive tool with documentation at this link: https://emapr.github.io/LT-GEE/\n",
    "\n",
    "This version uses the latest processing efforts of the Landsat TM+ ETM+ and OLI collection 2\n",
    "\n",
    "** this package allows the user to run GEE modules directly without the pitfalls of translating JS to Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c5da59-29d8-4d04-b844-6c654540831f",
   "metadata": {
    "id": "e6157fac-15c5-4016-b24e-3729960e6844"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import geemap.ml as ml\n",
    "from ipygee import chart as chart\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymannkendall as mk\n",
    "import xarray as xr\n",
    "import os\n",
    "# Import date class from datetime module\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb97ec-c96b-4312-9908-67f52483ec8f",
   "metadata": {},
   "source": [
    "# GEE Authentication \n",
    " \n",
    " ### Paste the Authetication code into the box below if prompted to save token\n",
    " \n",
    " \n",
    " (press enter to save token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4ac507-28df-4313-a67c-2db9fb8681ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "geemap.ee_initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034fa2eb-9d30-4074-9c46-e3c0a6a65889",
   "metadata": {},
   "source": [
    "### Inputs and Outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5f7582-8c3f-497b-b943-e681bdad137d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     17005\n",
       "1     18001\n",
       "2     20007\n",
       "3     21017\n",
       "4     21023\n",
       "      ...  \n",
       "90    79002\n",
       "91    79004\n",
       "92     8009\n",
       "93    93001\n",
       "94    94001\n",
       "Name: ID, Length: 95, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 catchments processed for hydroclimatic variables\n"
     ]
    }
   ],
   "source": [
    "p = '..'\n",
    "\n",
    "version = 'Version_3_20230303'\n",
    "\n",
    "l = pd.read_csv(f\"{p}/Inputs/{version}/GB.csv\").ID\n",
    "display(l)\n",
    "ls = l.tolist()\n",
    "\n",
    "print(f'{len(ls)} catchments processed for hydroclimatic variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be9e09-35db-4adb-92c7-5ebc78e231da",
   "metadata": {},
   "source": [
    "### Load the EE package\n",
    "\n",
    "The landTrendr package is developed to construct timeseries of landsat imagery for the purpose of land cover detection. The base parameters are optimised for deforestation event detection. \n",
    "\n",
    "This utilisation of the GEE asset (with apache license i.e. free for use) allows for the latest version of LandTrendr to be used. In contrast to early versions this allows for the utilisation of the Landsat Collection 2 reprocessing effort with improvements in cloud masking capabilities. Primarily we use \"ltgee.buildSRcollection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c702bf6-33c6-4c28-ba17-2eb15870d719",
   "metadata": {
    "id": "e6157fac-15c5-4016-b24e-3729960e6844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT! Please be advised:\n",
      "- This version of the Adapted_LT.js modules\n",
      "  uses some code adapted from the aut/or: @author Justin Braaten (Google) * @author Zhiqiang Yang (USDA Forest Service) * @author Robert Kennedy (Oregon State University)\n",
      "The latest edits to this code occur: 08/03/2023 for the adaptation efforts by @Mike OHanrahan (TU DELFT MSc research)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'version': 'string',\n",
       " 'buildSensorYearCollection': 'function',\n",
       " 'getSRcollection': 'function',\n",
       " 'getCombinedSRcollection': 'function',\n",
       " 'buildSRcollection': 'function',\n",
       " 'getCollectionIDlist': 'function',\n",
       " 'countClearViewPixels': 'function',\n",
       " 'buildClearPixelCountCollection': 'function',\n",
       " 'removeImages': 'function',\n",
       " 'LAIcol': 'function',\n",
       " 'calcIndex': 'function',\n",
       " 'standardize': 'function',\n",
       " 'transformSRcollection': 'function',\n",
       " 'createTrainingImage': 'function',\n",
       " 'addTerrainBand': 'function',\n",
       " 'genGCP': 'function',\n",
       " 'classifier': 'function',\n",
       " 'classArea': 'function'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oeel = geemap.requireJS()\n",
    "\n",
    "Map = geemap.Map()\n",
    "\n",
    "ltgee = geemap.requireJS(r'../JS_module/Adapted_LT_v6.js')\n",
    "\n",
    "ltgee.availability   # This command lists all the functions within the LandTrenr Module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484acd26-c655-4081-87b5-756c24f92c7a",
   "metadata": {},
   "source": [
    "## Initiate With a Shapefile\n",
    "\n",
    "This notebook assumes the user has a shapefile saved as an asset on their GEE, the assets used in the CATAPUCII project will be made publicly available in the @mohanrahan repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103ce65e-6dc2-4309-9cc8-e7374bf57af3",
   "metadata": {
    "id": "103ce65e-6dc2-4309-9cc8-e7374bf57af3"
   },
   "outputs": [],
   "source": [
    "asset_dir = 'projects/mohanrahan/assets'\n",
    "\n",
    "catchment_asset = 'CATAPUCII_Catchments/CAMELS_GB_catchment_boundaries'\n",
    "\n",
    "dataset = 'CAMELS_GB'\n",
    "\n",
    "col_string  = 'ID'\n",
    "\n",
    "crs = 'EPSG:27700'\n",
    "\n",
    "fignum = 0\n",
    "\n",
    "RGB_VIS = {'bands':['B3','B2','B1'], 'min':0, 'max':1.5e3}\n",
    "\n",
    "\n",
    "startYear = 1984\n",
    "\n",
    "endYear = 2022\n",
    "\n",
    "startDay = '06-20'\n",
    "\n",
    "endDay = '08-31'\n",
    "\n",
    "maskThese = ['cloud', 'shadow', 'snow',]\n",
    "\n",
    "bandList = [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B7\", \n",
    "           'NBR', 'NDMI', 'NDVI', 'NDSI', 'EVI','GNDVI', \n",
    "           'TCB', 'TCG', 'TCW', 'TCA', 'NDFI',] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24017ee3-b207-447c-938e-200892cfed46",
   "metadata": {},
   "source": [
    "## The Table Data\n",
    "\n",
    "- Here the table, a vector of catchments, is loaded from the users' assets in earth engine \n",
    "\n",
    "#TODO rewrite to a local .shp\n",
    "\n",
    "- The area is calculated of each shape and ranked per area, assuming that the largest is the most computationally expensive\n",
    "- This is done so that we can iterate from smallest to largest, or the opposite, should any memory issues become apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2489ce9f-28ce-41d7-94ee-c0b8a0e1477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pixel_area' 'area_km2' 'SOURCE' 'VERSION' 'ID' 'EXPORTED' 'ID_STRING']\n",
      "The length of the dataframe generated from the EE asset 95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_area</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>VERSION</th>\n",
       "      <th>ID</th>\n",
       "      <th>EXPORTED</th>\n",
       "      <th>ID_STRING</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000000000000000088</th>\n",
       "      <td>1355.679450</td>\n",
       "      <td>1349.764903</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27071</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>27071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000000000000235</th>\n",
       "      <td>1145.767150</td>\n",
       "      <td>1140.885961</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>71001</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>71001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000000000000001c0</th>\n",
       "      <td>1125.603290</td>\n",
       "      <td>1121.172318</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>54008</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>54008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000000000000207</th>\n",
       "      <td>897.948531</td>\n",
       "      <td>894.478359</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>62001</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>62001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000000000000025a</th>\n",
       "      <td>798.157955</td>\n",
       "      <td>794.507522</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>79002</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>79002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000000000000021b</th>\n",
       "      <td>12.768404</td>\n",
       "      <td>12.719149</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67010</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>67010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000000000000082</th>\n",
       "      <td>11.353532</td>\n",
       "      <td>11.304831</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27047</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>27047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000000000000001df</th>\n",
       "      <td>10.506362</td>\n",
       "      <td>10.466687</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>55008</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>55008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000000000000084</th>\n",
       "      <td>8.177400</td>\n",
       "      <td>8.143164</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27051</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>27051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000000000000000c6</th>\n",
       "      <td>4.316773</td>\n",
       "      <td>4.299710</td>\n",
       "      <td>National River Flow Archive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>31023</td>\n",
       "      <td>1518422400000</td>\n",
       "      <td>31023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pixel_area     area_km2                       SOURCE  \\\n",
       "system_index                                                                  \n",
       "00000000000000000088  1355.679450  1349.764903  National River Flow Archive   \n",
       "00000000000000000235  1145.767150  1140.885961  National River Flow Archive   \n",
       "000000000000000001c0  1125.603290  1121.172318  National River Flow Archive   \n",
       "00000000000000000207   897.948531   894.478359  National River Flow Archive   \n",
       "0000000000000000025a   798.157955   794.507522  National River Flow Archive   \n",
       "...                           ...          ...                          ...   \n",
       "0000000000000000021b    12.768404    12.719149  National River Flow Archive   \n",
       "00000000000000000082    11.353532    11.304831  National River Flow Archive   \n",
       "000000000000000001df    10.506362    10.466687  National River Flow Archive   \n",
       "00000000000000000084     8.177400     8.143164  National River Flow Archive   \n",
       "000000000000000000c6     4.316773     4.299710  National River Flow Archive   \n",
       "\n",
       "                     VERSION     ID       EXPORTED ID_STRING  \n",
       "system_index                                                  \n",
       "00000000000000000088     1.3  27071  1518422400000     27071  \n",
       "00000000000000000235     1.3  71001  1518422400000     71001  \n",
       "000000000000000001c0     1.3  54008  1518422400000     54008  \n",
       "00000000000000000207     1.3  62001  1518422400000     62001  \n",
       "0000000000000000025a     1.3  79002  1518422400000     79002  \n",
       "...                      ...    ...            ...       ...  \n",
       "0000000000000000021b     1.3  67010  1518422400000     67010  \n",
       "00000000000000000082     1.3  27047  1518422400000     27047  \n",
       "000000000000000001df     1.3  55008  1518422400000     55008  \n",
       "00000000000000000084     1.3  27051  1518422400000     27051  \n",
       "000000000000000000c6     1.3  31023  1518422400000     31023  \n",
       "\n",
       "[95 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = ee.FeatureCollection(f\"{asset_dir}/{catchment_asset}\")\n",
    "\n",
    "def set_area_km2(feature):\n",
    "    '''\n",
    "    Calculate the area of each geometry in square kilometer\n",
    "    '''\n",
    "    area = feature.geometry().area().divide(1000*1000)\n",
    "    setting = feature.set('area_km2', area)\n",
    "    return setting\n",
    "\n",
    "def set_area_pixel(feature):\n",
    "    aoi = feature.geometry()\n",
    "    area = ee.Image.pixelArea().divide(1e6).clip(aoi).select('area').reduceRegion(**{\n",
    "        'reducer':ee.Reducer.sum(),\n",
    "        'geometry':aoi,\n",
    "        'scale':30,\n",
    "        'crs':crs,\n",
    "        'maxPixels':1e13,\n",
    "        'bestEffort':True,\n",
    "        }).get('area')\n",
    "    setting = feature.set('pixel_area', area)\n",
    "    return setting\n",
    "\n",
    "def set_id(feature):\n",
    "    '''\n",
    "    Set the system ID as a column\n",
    "    '''\n",
    "    getting_name = ee.String(feature.get('system:index'))\n",
    "    setting_id = feature.set({'system_index':getting_name,})\n",
    "    return setting_id\n",
    "\n",
    "table_area = table.map(set_area_km2).map(set_id).map(set_area_pixel)\n",
    "\n",
    "Filtered_Sorted = table_area.filter(ee.Filter.gt('area_km2', 0)).sort('area_km2', False)  # true ranks from smallest to largest\n",
    "\n",
    "down = geemap.ee_to_pandas(Filtered_Sorted).set_index(['system_index'])\n",
    "\n",
    "print(down.keys().values)\n",
    "\n",
    "df1 = down.loc[down['ID'].isin(ls)]\n",
    "\n",
    "print(f'The length of the dataframe generated from the EE asset {len(df1)}')\n",
    "\n",
    "sys_index = df1.index.to_list()\n",
    "\n",
    "display(df1)\n",
    "\n",
    "#df1.loc[sys_index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416aaae7-dea1-4d0b-98ce-166f08b7338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of catchments with Hydroclimatic indices calculated match the length filtered EE asset\n",
      "There seems to be no mismatch\n",
      "Continue... \n"
     ]
    }
   ],
   "source": [
    "len1 = len(df1.ID.values)\n",
    "len2 = len(ls)\n",
    "\n",
    "if len1 > len2:\n",
    "    print(f'catchment{ set(df1.station_re.values).symmetric_difference(ls)} is/are missing from the catchment sets')\n",
    "elif len2 >len1:\n",
    "    print(f'catchment{ set(df1.station_re.values).symmetric_difference(ls)} is/are missing from the EE asset')\n",
    "else:\n",
    "    print('The number of catchments with Hydroclimatic indices calculated match the length filtered EE asset\\nThere seems to be no mismatch\\nContinue... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8203b3-aab7-4442-bd54-bcdee88b909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geemap.ee_to_pandas(Filtered_Sorted)\n",
    "\n",
    "if not os.path.exists(f'../Outputs/{dataset}/'):\n",
    "    os.makedirs(f'../Outputs/{dataset}/')\n",
    "\n",
    "gdf.to_excel(f'../Outputs/{dataset}/{dataset}_catchment_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3b14bc-82cf-4d8e-8deb-7a15df1a5368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2ad48f5b664c459249c8e415fa7df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[53.49722684216607, -2.3029239738111555], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "# Map.setOptions('TERRAIN')\n",
    "Map.addLayer(Filtered_Sorted.filter(ee.Filter.inList('ID', ee.List(ls)).Not()), {'color':'red'}, 'red: Not Included')\n",
    "Map.addLayer(Filtered_Sorted.filter(ee.Filter.inList('ID', ee.List(ls))), {'color': 'green'}, 'green: Included')\n",
    "Map.centerObject(Filtered_Sorted, 6)\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec43c4c-115d-4483-bb47-8c8994832a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_collection(image: ee.Image)-> ee.Image:\n",
    "    \n",
    "    \"\"\"\n",
    "    reduce the size of the image colelction to be only pixels relevant to the aoi\n",
    "    \"\"\"\n",
    "    return image.clip(aoi).copyProperties(image)\n",
    "\n",
    "def image_band_mean(imageCollection, scale, band):\n",
    "    \n",
    "    chart_ts_region = chart.Image.series(**{\n",
    "    'imageCollection': imageCollection,\n",
    "    'reducer': ee.Reducer.mean(),\n",
    "    'region': aoi,\n",
    "    'scale': scale,\n",
    "    'band': band+'_mean',\n",
    "    })\n",
    "    \n",
    "    return chart_ts_region.dataframe\n",
    "\n",
    "def image_band_median(imageCollection, scale, band):\n",
    "    \n",
    "    chart_ts_region = chart.Image.series(**{\n",
    "    'imageCollection': imageCollection,\n",
    "    'reducer': ee.Reducer.median(),\n",
    "    'region': aoi,\n",
    "    'scale': scale,\n",
    "    'band': band+'_median',\n",
    "    })\n",
    "    \n",
    "    return chart_ts_region.dataframe\n",
    "\n",
    "def image_band_percentile_5(imageCollection, scale, band):\n",
    "    \n",
    "    chart_ts_region = chart.Image.series(**{\n",
    "    'imageCollection': imageCollection,\n",
    "    'reducer': ee.Reducer.percentile([5]),\n",
    "    'region': aoi,\n",
    "    'scale': scale,\n",
    "    'band': band+'_p5',\n",
    "    })\n",
    "    \n",
    "    return chart_ts_region.dataframe\n",
    "\n",
    "def image_band_percentile_95(imageCollection, scale, band):\n",
    "    \n",
    "    chart_ts_region = chart.Image.series(**{\n",
    "    'imageCollection': imageCollection,\n",
    "    'reducer': ee.Reducer.percentile([95]),\n",
    "    'region': aoi,\n",
    "    'scale': scale,\n",
    "    'band': band+'_p95',\n",
    "    })\n",
    "    \n",
    "    return chart_ts_region.dataframe\n",
    "\n",
    "    \n",
    "def bands_reduced_toexcel(imcol, scale, ind, band):\n",
    "    '''\n",
    "    Takes the bands and returns excel sheets of each catchment:\n",
    "    ->mean, median, percentile, \n",
    "    '''\n",
    "    df_mean = image_band_mean(imcol, scale, band)\n",
    "    df_median = image_band_median(imcol, scale, band)\n",
    "    df_pct5 = image_band_percentile_5(imcol, scale, band)\n",
    "    df_pct95 = image_band_percentile_95(imcol, scale, band)\n",
    "    \n",
    "    \n",
    "    df_mean.reset_index()\n",
    "    df_median.reset_index()\n",
    "    df_pct5.reset_index()\n",
    "    df_pct95.reset_index()\n",
    "    \n",
    "    \n",
    "    joined= df_mean.join(df_median, how='inner', lsuffix='mean', rsuffix='median')\n",
    "    joined_pct = df_pct5.join(df_pct95, how='inner', lsuffix='p5', rsuffix='p95')\n",
    "   \n",
    "    annual = joined.join(joined_pct, how='inner')\n",
    "    annual.to_excel(f'../Outputs/{dataset}/SR_timeseries/{ind}_annual_{band}.xlsx')\n",
    "\n",
    "def extractArea(item):\n",
    "    \n",
    "    '''\n",
    "    Method borrowed from https://code.earthengine.google.co.in/9c45ff677c46eae08952831de02bfb40\n",
    "    Article: https://spatialthoughts.com/2020/06/19/calculating-area-gee/\n",
    "    '''\n",
    "    \n",
    "    areaDict = ee.Dictionary(item)\n",
    "    classNumber = ee.Number(areaDict.get('classification')).format()\n",
    "    area = ee.Number(areaDict.get('sum')).divide(1e6)\n",
    "    return ee.List([classNumber, area])\n",
    "\n",
    "def classArea(classified_image, scale):\n",
    "    '''\n",
    "    This function takes the pixel areas represented by each class the landsat scale is 30m but,\n",
    "    nominal scale of image is 111000m after medoid compositing\n",
    "    '''\n",
    "    \n",
    "    areaImage = ee.Image.pixelArea().addBands(classified_image)\n",
    "    \n",
    "    areas = areaImage.reduceRegion(**{\n",
    "            'reducer':ee.Reducer.sum().group(**{'groupField':1, 'groupName':'classification'}),\n",
    "            'geometry':aoi,\n",
    "            'scale':scale,\n",
    "            'maxPixels':1e10,\n",
    "            'bestEffort':True,\n",
    "    })\n",
    "    \n",
    "    classAreas = ee.List(areas.get('groups'))\n",
    "    \n",
    "    classAreasLists = classAreas.map(extractArea)\n",
    "    \n",
    "    return classAreasLists\n",
    "\n",
    "def msToDate(milliseconds):\n",
    "    base_datetime = datetime.datetime(1970, 1, 1)\n",
    "    delta = datetime.timedelta(0, 0, 0, milliseconds)\n",
    "    target_datetime = base_datetime + delta\n",
    "    return target_datetime\n",
    "\n",
    "def dataframeAreas(i, yc, classified, trainingClassImage, ms, classImageYear, name, accuracy, pixArea):\n",
    "\n",
    "    ls1 = pd.DataFrame(classArea(classified, 30).getInfo(), columns=['class', 'area_RF'])\n",
    "    ls2 = pd.DataFrame(classArea(trainingClassImage, 100).getInfo(), columns=['class', 'area_CORINE'])\n",
    "\n",
    "    merged = ls1.merge(ls2, how='inner', on='class')\n",
    "    merged['image_date'] = ms\n",
    "    pivoted = merged.pivot(index='image_date', columns='class', values=['area_CORINE', 'area_RF'])\n",
    "    pivoted['training', 'year_trained'] =  classImageYear\n",
    "    pivoted['area_CORINE', '6'] = 0\n",
    "    pivoted['catchment', 'area'] = pixArea\n",
    "    pivoted['area_RF', '6'] = pivoted.catchment.area - pivoted.iloc[0, 6:10].sum() \n",
    "    pivoted['catchment', 'name '] = name\n",
    "    pivoted['testing', 'accuracy'] = accuracy\n",
    "    pivoted['ind'] = str(i)+'_'+str(yc)\n",
    "    pivoted.fillna(0)\n",
    "    \n",
    "    return pivoted\n",
    "\n",
    "def normalize (image):\n",
    "    '''\n",
    "    This function is used to convert band values to a range between 0 and 1 via normalisation,\n",
    "    this is typically slow and no improvement to accuracy has been observed yet by its implementation.\n",
    "    \n",
    "    The 5 minute loop for an example catchment e.g. Chooz 2012, goes from \n",
    "    '''\n",
    "    bandNames = image.bandNames()\n",
    "    \n",
    "def saveClassifierToCSV(classifier, name, yc):\n",
    "    decisionTrees = ee.List(classifier.explain().get('trees')).getInfo()\n",
    "    folder='Trees'\n",
    "\n",
    "    var = f'../Outputs/{dataset}/{folder}/'\n",
    "\n",
    "    if not os.path.exists(var):\n",
    "        print('created')\n",
    "        os.makedirs(var)\n",
    "\n",
    "    ml.trees_to_csv(decisionTrees, f'../Outputs/Meuse/Trees/{name}_{yc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c779e0-9807-4af9-a24a-302968c81417",
   "metadata": {
    "id": "cc5da96b-d9f7-4042-b21c-1aed2be24d8e"
   },
   "source": [
    "## Running Module over the Shapefile\n",
    "\n",
    "1. The geometries are called by their system indices (sys_index) updating the 'aoi' and running the process over any  using the indices included in the \n",
    "2. The image collection is generated per shapefile and then returns the decadal mean of each index\n",
    "\n",
    "# TODO:\n",
    "\n",
    "- Redefine the methodology of reduction. Using chart --> dataframe --> join all dataframes is redundant an probably very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7e8102-c6b4-4431-92f3-ce47858dd242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_ls = 'used_images'\n",
    "SR_t = 'SR_timeseries'\n",
    "RF_c = 'RF_classification/'\n",
    "\n",
    "\n",
    "folder_list = [id_ls, SR_t, RF_c]\n",
    "\n",
    "for folder in folder_list:\n",
    "    \n",
    "    var = f'../Outputs/{dataset}/{folder}'\n",
    "    \n",
    "    if not os.path.exists(var):\n",
    "        print('created')\n",
    "        os.makedirs(var)\n",
    "\n",
    "c_1990 = ml.csv_to_classifier('../Outputs/Meuse/Trees/Chooz_1990')\n",
    "c_2000 = ml.csv_to_classifier('../Outputs/Meuse/Trees/Chooz_2000')\n",
    "c_2006 = ml.csv_to_classifier('../Outputs/Meuse/Trees/Chooz_2006')\n",
    "c_2012 = ml.csv_to_classifier('../Outputs/Meuse/Trees/Chooz_2012')\n",
    "c_2018 = ml.csv_to_classifier('../Outputs/Meuse/Trees/Chooz_2018')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47e37419-ad01-4be6-b49e-732d70079fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tuning of hyperParameters 'rfParams' is accomplished using this link:\n",
    "\n",
    "https://code.earthengine.google.com/a1b6b96f28dc3c8998dcc74962b0eb51\n",
    "\n",
    "JSON printed in the console was plotted in python to find the optimal parameters for \n",
    "this purpose. Specifically two years were plotted for the Chooz catchment 1990 vs 2018.\n",
    "\n",
    "The optimal parameter for each year was identified using overall accuaracy and overall kappa score\n",
    "Optimal parameter set for all years was determined to be between each.\n",
    "\n",
    "The parameters are hard coded into the JS module:\n",
    "\n",
    "Number of trees = 190\n",
    "Varibles per split = 9\n",
    "Minimum leaf population = 18\n",
    "Bag fraction =  0.7\n",
    "Max nodes = 400\n",
    "Seed = 0\n",
    "\n",
    "This results in an accuracy ranging from 84-86% max over the years\n",
    "\n",
    "'''\n",
    "\n",
    "classLoopParams = {'dataset':'CORINE', \n",
    "               'trainingClassLevel':1,\n",
    "               'customClassLevels':None,\n",
    "               'numClasses':5,            #if trainingClassLevel is 1 then there are 5 classes, level is 2 then there are 15, 3 is 44. (CORINE land cover class grouping)\n",
    "               'split':0.7,               #split the training and testing 0.7/0.3 (70% training, 30% accuracy testing). \n",
    "               'tileScale':10,            #tileScale higher number reduces likelihood of classifier running into a memory limit\n",
    "              }\n",
    "\n",
    "scale = 5000 # define the pixel size for reducing, in meters, initially high to reduce comp time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6f5f4-fb25-4435-b90c-2786a40ab8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin loop: 2023-04-01 20:45:21.165099\n",
      "\n",
      "1/95 2023-04-01 20:45:21.168091\n",
      "Dataset: CAMELS_GB, \n",
      "Catchment: 71001, \n",
      "Surface Reflectance Processing ...\n",
      "\n",
      "saving bands to excel\n",
      "calculating LAI\n",
      "getting ID collection\n",
      "step 1: Surface reflectance exported: 2023-04-01 20:47:37.219646 \n",
      "Time taken: 0:02:16.051555\n",
      "\n",
      "step 2: Initialize classification routine: 2023-04-01 20:47:37.219646\n",
      "1986 classified using: 2000 ...  \n",
      "accuracy: 0.385\n",
      "1985 classified using: 2000 ...  \n",
      "accuracy: 0.582\n",
      "1986 classified using: 2000 ...  \n",
      "accuracy: 0.385\n",
      "1994 classified using: 2000 ...  \n",
      "accuracy: 0.478\n",
      "1995 classified using: 2000 ...  \n",
      "accuracy: 0.697\n",
      "1996 classified using: 2000 ...  \n",
      "accuracy: 0.516\n",
      "2004 classified using: 2006 ...  \n",
      "accuracy: 0.440\n",
      "2005 classified using: 2006 ...  \n",
      "accuracy: 0.561\n",
      "2006 classified using: 2006 ...  \n",
      "accuracy: 0.451\n",
      "2014 classified using: 2012 ...  \n",
      "accuracy: 0.449\n",
      "2015 classified using: 2018 ...  \n",
      "accuracy: 0.634\n",
      "2016 classified using: 2018 ...  \n",
      "accuracy: 0.631\n",
      "step2: Done: 2023-04-01 21:26:03.716147, time taken: 0:38:26.496501\n",
      "\n",
      "Catchment: 71001, total time: 0:40:42.548056\n",
      "---------------\n",
      "\n",
      "2/95 2023-04-01 21:26:03.716147\n",
      "Dataset: CAMELS_GB, \n",
      "Catchment: 54008, \n",
      "Surface Reflectance Processing ...\n",
      "\n",
      "saving bands to excel\n",
      "calculating LAI\n"
     ]
    }
   ],
   "source": [
    "t0 = dt.today()\n",
    "\n",
    "classArea_df = pd.DataFrame()\n",
    "\n",
    "print(f'begin loop: {t0}')\n",
    "\n",
    "for i, ind in enumerate(sys_index[1:]):\n",
    "\n",
    "    \n",
    "    name = df1.loc[ind].ID\n",
    "    \n",
    "    area = df1.loc[ind].area_km2\n",
    "    \n",
    "    pix_area = df1.loc[ind].pixel_area\n",
    "    \n",
    "    t1 = dt.today()\n",
    "    \n",
    "    print(f'\\n{i+1}/{len(sys_index)} {t1}\\nDataset: {dataset}, \\nCatchment: {name}, \\nSurface Reflectance Processing ...\\n')\n",
    "    \n",
    "    aoi = Filtered_Sorted.filter(ee.Filter.eq('system:index', ind))\n",
    "    \n",
    "    annual_med = ltgee.buildSRcollection(startYear, endYear, startDay, endDay, aoi, maskThese)\n",
    "    \n",
    "    annual_med_calc = ltgee.transformSRcollection(annual_med, bandList)\n",
    "    print('saving bands to excel')\n",
    "    band_calc_df = bands_reduced_toexcel(ee.ImageCollection(annual_med_calc), scale, ind, 'B1')\n",
    "    \n",
    "    print('calculating LAI')\n",
    "    \n",
    "    col = ee.ImageCollection(ltgee.LAIcol(startYear, endYear, startDay, endDay, aoi)) \n",
    "    \n",
    "    lai_calc_df = bands_reduced_toexcel(col, col.first().projection().nominalScale().getInfo(), ind, 'LAI')\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Which images are used in creating the annual composites?\n",
    "    -> return as a list of Landsat image IDs ** \n",
    "    ** can be used for exclusion if image quality is suboptimal upon later inspection.. important for small sample cases.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    id_key = 'idList'\n",
    "    \n",
    "    masked_col_key = 'collection'\n",
    "    \n",
    "    print('getting ID collection')\n",
    "    \n",
    "#     GetCollectionID = ltgee.getCollectionIDlist(startYear, endYear, startDay, endDay, aoi)\n",
    "    \n",
    "#     im_id_list = GetCollectionID[id_key]\n",
    "    \n",
    "#     image_list = pd.DataFrame({f'{name}': im_id_list.getInfo()})\n",
    "    \n",
    "#     image_list.to_csv(f'../Outputs/{dataset}/used_images/{ind}_imageList.csv')\n",
    "    \n",
    "    \n",
    "    t2 = dt.today()\n",
    "    \n",
    "    print(f'step 1: Surface reflectance exported: {t2} \\nTime taken: {t2-t1}')\n",
    "    \n",
    "    t3 = dt.today()\n",
    "    \n",
    "    print(f'\\nstep 2: Initialize classification routine: {t3}')\n",
    "    \n",
    "    \n",
    "    if dataset == 'CAMELS_GB':\n",
    "        '''\n",
    "        \n",
    "        The years that we train on are not necessarily the same as the years we classify: \n",
    "        - first define the years to return that will be relevant to the decadal analysis (matching the hydroclimatic decades)\n",
    "        - Then use conditions to define which training set corresponds best to the image to be classified. \n",
    "        - LATER: Will need to use a trained classifier, perhaps the 'best performer', to classify the USA dataset. \n",
    "            - Best accuracy may be to take a classifier that samples all 4 categories\n",
    "        \n",
    "        '''\n",
    "        # year_classified = np.arange(1984, 2018)\n",
    "        year_classified = [1986,1985,1986, 1994,1995,1996,2004,2005,2006,2014,2015,2016]\n",
    "        \n",
    "        for j, yc in enumerate(year_classified):\n",
    "            '''\n",
    "            Define the training image, then the image to classify, adding slope and elevation bands\n",
    "\n",
    "            Corine Representative Classes GB:\n",
    "            || 1989 -> 1998 | 1999 -> 2001 | 2005 -> 2007 | 2011 -> 2012 | 2017 -> 2018 ||\n",
    "            ||   \"2000   |    \"2000\"    |    \"2006\"    |     \"2012\"   |     \"2018\"   ||\n",
    "\n",
    "            Training \"image year above\" --> classify the relevant Landsat date range below:\n",
    "            || 1984 -> 1998 | 1999 -> 2003 | 2004 -> 2009 | 2010 -> 2014 | 2015 -> ...  || \n",
    "            '''\n",
    "            if yc >= 1984 and yc < 1999:\n",
    "                classifier = c_1990\n",
    "                classImageYear = 2000\n",
    "\n",
    "            elif yc >= 1999 and yc < 2004:\n",
    "                classifier = c_2000\n",
    "                classImageYear = 2000\n",
    "\n",
    "            elif yc >= 2004 and yc < 2010:\n",
    "                classifier = c_2006\n",
    "                classImageYear = 2006\n",
    "\n",
    "            elif yc >= 2010 and yc < 2015:\n",
    "                classifier = c_2012\n",
    "                classImageYear = 2012\n",
    "\n",
    "            elif yc >= 2015:\n",
    "                classifier = c_2018\n",
    "                classImageYear = 2018\n",
    "\n",
    "            else:\n",
    "                print('ERROR: year to classify out of range[1984 - 2022]')\n",
    "                break\n",
    "            \n",
    "            #the image from the collection that we want to classify\n",
    "            imageFromCollection = ee.ImageCollection(annual_med_calc).filterDate(str(yc)+'-'+startDay, str(yc+1)+'-'+endDay).first().clip(aoi)\n",
    "            \n",
    "            #image from training dataset e.g. CORINE is selected and simlified... \n",
    "            trainingClassImage = ltgee.createTrainingImage(str(classImageYear), classLoopParams['dataset'], classLoopParams['trainingClassLevel'], aoi)\n",
    "            \n",
    "            \n",
    "            #Adding the elevation and slope band calculations to each image\n",
    "            imageToClassify = ltgee.addTerrainBand(imageFromCollection, aoi)\n",
    "            \n",
    "            #getting the date of the image and converting it from milliseconds since 1970 (Earth engines preferred datetime)\n",
    "            ms = msToDate(ee.Date(imageToClassify.get('system:time_start')).getInfo()['value'])\n",
    "            \n",
    "            #the points used for training the classifier are randomly distibuted amongst the classes extracting a profile of spectral and terrain\n",
    "            points = ltgee.genGCP(trainingClassImage, imageToClassify, classLoopParams['numClasses'], classLoopParams['split'], classLoopParams['tileScale'], aoi, 'weighted')\n",
    "            \n",
    "            # 70% of the points are allocated to training\n",
    "            training = points['training']\n",
    "            \n",
    "            #30% of the points are allocated to classification\n",
    "            testing = points['testing']\n",
    "            \n",
    "            t5 = dt.today()\n",
    "            \n",
    "            # classifier training with predefined number of trees using training points\n",
    "            # classifier = ltgee.classifier(imageToClassify, training)\n",
    "            \n",
    "            t6 = dt.today()\n",
    "            \n",
    "            #saving decision trees for later use\n",
    "            # saveClassifierToCSV(classifier, name, yc)\n",
    "            \n",
    "#             #classifying image using the training\n",
    "            classified = imageToClassify.classify(classifier)\n",
    "            \n",
    "            focal = classified.focalMode(**{'radius':30,\n",
    "                                          'kernelType':'square',\n",
    "                                          'units':'meters',\n",
    "                                          'iterations':2}).clip(aoi)\n",
    "            \n",
    "            # Map.addLayer(focal, {'bands':['classification'], 'min':1, 'max':5, 'palette':['#E6004D', '#FFFFA8', '#80FF00', '#A6A6FF', '#00CCF2']}, f'{name} RF:{j}.{yc}.{classImageYear}')\n",
    "\n",
    "#           #assess the accuracy using the testing points, see where the confusion occurs\n",
    "            accuracy = testing.classify(classifier).errorMatrix('landcover', 'classification').accuracy().getInfo()\n",
    "            print(f'{yc} classified using: {classImageYear} ...  \\naccuracy: {accuracy:.3f}')\n",
    "\n",
    "\n",
    "            df = dataframeAreas(i, j, classified, trainingClassImage, ms, classImageYear, name, accuracy, pix_area)\n",
    "            \n",
    "            df.to_csv(f'../Outputs/{dataset}/RF_classification/{ind}_{yc}_classes.csv')\n",
    "            \n",
    "            classArea_df = classArea_df.append(df)\n",
    "            \n",
    "    else:\n",
    "        print('classification routine for this dataset is not yet provided for')\n",
    "    \n",
    "    t4 = dt.today()\n",
    "    \n",
    "    print(f'step2: Done: {t4}, time taken: {t4-t3}')\n",
    "    \n",
    "    print(f'\\nCatchment: {name}, total time: {t4-t1}\\n---------------')\n",
    "    \n",
    "#     if ind == sys_index[0]:\n",
    "#         break\n",
    "\n",
    "\n",
    "\n",
    "tfinal = dt.today()\n",
    "\n",
    "print(f'END LOOP: Full routine finished: {tfinal} \\nTime taken: {tfinal-t0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d9be1-b27d-4477-b487-9e5fa2f12440",
   "metadata": {},
   "source": [
    "## Trend analysis per band\n",
    "\n",
    "- can we look at median band collection and percentile bounds, reduced to a per kilometer scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69108d-1a05-4183-ba4b-bd581207ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vis = {'bands':['landcover'], 'min':1, 'max':5, 'palette':['#E6004D', '#FFFFA8', '#80FF00', '#A6A6FF', '#00CCF2']}\n",
    "\n",
    "class_vis = {'bands':['classification'], 'min':1, 'max':5, 'palette':['#E6004D', '#FFFFA8', '#80FF00', '#A6A6FF', '#00CCF2']}\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi)\n",
    "Map.addLayer(aoi)\n",
    "Map.addLayer(imageToClassify, RGB_VIS, 'RGB')\n",
    "Map.addLayer(trainingClassImage, train_vis, 'Train')\n",
    "Map.addLayer(classified, class_vis, 'Class')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156ddb2-4d76-4887-82d2-8c9c6b263439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
